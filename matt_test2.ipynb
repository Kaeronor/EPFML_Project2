{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os,sys\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import timeit\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 400, 400, 3) (100, 400, 400)\n"
     ]
    }
   ],
   "source": [
    "# Directory and files name\n",
    "train_dir = \"training/\"\n",
    "tr_image_dir = train_dir + \"images/\"\n",
    "tr_label_dir = train_dir + \"groundtruth/\"\n",
    "\n",
    "tr_image_files = os.listdir(tr_image_dir)\n",
    "tr_label_files = os.listdir(tr_label_dir)\n",
    "\n",
    "# Number of training samples\n",
    "N = len(tr_image_files)\n",
    "\n",
    "# Load the images and ground truth\n",
    "img_train = []\n",
    "label_train = []\n",
    "for i in range(N):\n",
    "    img = mpimg.imread(tr_image_dir + tr_image_files[i])\n",
    "    label = mpimg.imread(tr_label_dir + tr_label_files[i])\n",
    "    \n",
    "    img_train.append(img)\n",
    "    label_train.append(label)\n",
    "\n",
    "# Keep only sub-set of images\n",
    "NUM_IMAGES = N\n",
    "\n",
    "img_train = np.asarray(img_train[:NUM_IMAGES])\n",
    "label_train = np.asarray(label_train[:NUM_IMAGES])\n",
    "\n",
    "print(img_train.shape, label_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 400\n",
    "PATCH_SIZE = 16\n",
    "WINDOW_SIZE = 52 # 18px - PATCH_SIZE - 18px\n",
    "NB_WINDOWS = (IMG_SIZE/PATCH_SIZE)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mirror_boundary_conditions(coord, dim):\n",
    "    \"\"\"\n",
    "    Return the correct coordinate according to mirror boundary conditions\n",
    "        coord: a coordinate (x or y) in the image\n",
    "        dim: the length of the axis of said coordinate\n",
    "    \"\"\"\n",
    "    # If the coordinate is outside of the bounds of the axis, take its reflection inside the image\n",
    "    if coord < 0:\n",
    "        coord = -coord\n",
    "    elif coord >= dim:\n",
    "        coord =  2*(dim-1) - coord % (2*(dim-1))\n",
    "    # Else, do nothing\n",
    "    return int(coord)\n",
    "\n",
    "def get_window(image, window_size, corner_coordinates, patch_size):\n",
    "    \"\"\"\n",
    "    Get a window in image, centered on a patch, taking into account boundary conditions\n",
    "        image: a numpy array representing our image\n",
    "        window_size: an even number specifying the size of the window\n",
    "        corner_coordinates: a list containing the x-y coordinates of the patch's upleft pixel\n",
    "        path_size: an even number specifying the size of the central patch\n",
    "    \"\"\"\n",
    "    # Get convenient variables\n",
    "    window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    nrows, ncols, nchannels = image.shape\n",
    "    window = np.zeros((window_size, window_size, nchannels))\n",
    "    \n",
    "    # Fill in the window array with pixels of the image\n",
    "    for i in range(window_size):\n",
    "        # Apply mirror boundary conditions on the x-coordinate\n",
    "        i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i, nrows)\n",
    "        for j in range(window_size):\n",
    "            # Same for the y-coordinate\n",
    "            j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j, ncols)\n",
    "            # Fill in the window with the corresponding pixel\n",
    "            window[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_to_the_right(image, window, corner_coordinates, patch_size):\n",
    "    nrows, ncols, _ = image.shape\n",
    "    window_size = len(window)\n",
    "    #window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    step = patch_size\n",
    "    \n",
    "    shifted = np.roll(window, -step, axis=1)\n",
    "    for i in range(window_size):\n",
    "        i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i, nrows)            \n",
    "        for j in range(window_size-step, window_size):\n",
    "            j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j + step, ncols)\n",
    "            shifted[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return shifted\n",
    "\n",
    "def shift_to_the_bottom(image, window, corner_coordinates, patch_size):\n",
    "    nrows, ncols, _ = image.shape\n",
    "    window_size = len(window)\n",
    "    #window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    step = patch_size\n",
    "    \n",
    "    shifted = np.roll(window, -step, axis=0)\n",
    "    for j in range(window_size):\n",
    "        j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j, ncols)\n",
    "        for i in range(window_size-step, window_size):\n",
    "            i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i + step, nrows)\n",
    "            shifted[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return shifted\n",
    "\n",
    "def sliding_window(image, window_size, patch_size):\n",
    "    \"\"\"\n",
    "    Construct a list of sliding windows of given size on an image.\n",
    "    The windows, centered on a patch, will slide from left to right and from up to down.\n",
    "        image: a numpy array representing our image\n",
    "        window_size: an even number specifying the size of the window\n",
    "        patch_size: the size of the central patch\n",
    "    \"\"\"\n",
    "    nrows, ncols, _ = image.shape\n",
    "    windows = []\n",
    "    i = 0\n",
    "    row_windows = [get_window(image, window_size, [i, 0], patch_size)]\n",
    "    for j in range(patch_size, ncols-1, patch_size):\n",
    "        #print(j)\n",
    "        row_windows += [shift_to_the_right(image, row_windows[-1], [i, j], patch_size)]\n",
    "    windows += row_windows\n",
    "    #print('===')\n",
    "    for i in range(patch_size, nrows-1, patch_size):\n",
    "        #print(i)\n",
    "        row_windows = [shift_to_the_bottom(image, row_windows[int(j/patch_size)], [i, j], patch_size) \n",
    "                       for j in range(0, ncols-1, patch_size)]\n",
    "        #print(len(row_windows))\n",
    "        windows += row_windows\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im = img_train[0]\n",
    "#for window_size in [3, 5, 7, 15, 35, 51]:\n",
    "#    %timeit sliding_window(im, window_size, step=int(window_size/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_windows(img_train, label_train, window_size, step):\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    for im, labels, i in zip(img_train, label_train, range(len(img_train))):\n",
    "        w_im = sliding_window(im, window_size, step)\n",
    "        w_labels = sliding_window(labels[:, :, np.newaxis], window_size, step)\n",
    "        train_data += w_im\n",
    "        train_labels += w_labels\n",
    "        path = './windows_train/' + str(i)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        for wi, wl, j in zip(w_im, w_labels, range(len(w_im))):\n",
    "            img_name = path + '/im_' + str(j) + '.png'\n",
    "            plt.imsave(img_name, wi)\n",
    "            label_name = path + '/label_' + str(j) + '.png'\n",
    "            plt.imsave(label_name, wl[:,:,0])\n",
    "    return train_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(img_train, window_size, patch_size):\n",
    "    train_data = []\n",
    "    #train_labels = []\n",
    "    for im, i in zip(img_train, range(len(img_train))):\n",
    "        w_im = sliding_window(im, window_size, patch_size)\n",
    "        #w_labels = sliding_window(labels[:, :, np.newaxis], window_size, step)\n",
    "        train_data += w_im\n",
    "        #train_labels += w_labels\n",
    "        path = './windows_train_patch/' + str(i)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        for wi, j in zip(w_im, range(len(w_im))):\n",
    "            img_name = path + '/im_' + str(j) + '.png'\n",
    "            plt.imsave(img_name, wi)\n",
    "            #label_name = path + '/label_' + str(j) + '.png'\n",
    "            #plt.imsave(label_name, wl[:,:,0])\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = compute(img_train, WINDOW_SIZE, PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Put the patch labels in train_labels then feed that sh\\*t to the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = np.array(train_data)\n",
    "train_l = np.array(train_labels)[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = train_d.reshape((len(train_data)*51, 51, 3))\n",
    "train_l = train_l.reshape((len(train_labels)*51, 51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#a = np.array(range(10*10))\n",
    "#a = a.reshape((10, 10))\n",
    "#print(a)\n",
    "#aa = get_window(a[:,:,np.newaxis], 5, [5,5])[:,:,0]\n",
    "#print('\\n')\n",
    "#print(aa)\n",
    "#print('\\n')\n",
    "#print(shift_to_the_bottom(a[:,:,np.newaxis], aa[:,:,np.newaxis], [5,5], 2)[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "IMG_PATCH_SIZE = 51\n",
    "TRAINING_SIZE = 27300\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 15\n",
    "a = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LeakyReLU, Input, Reshape, Permute, Average\n",
    "from keras.layers import Conv2D, MaxPooling2D, Concatenate, Lambda, Activation, GlobalAveragePooling2D, Conv2DTranspose, GlobalAveragePooling1D\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, 2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "model.add(LeakyReLU(alpha=a))\n",
    "model.add(Conv2D(32, 2))\n",
    "model.add(LeakyReLU(alpha=a))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, 2))\n",
    "model.add(LeakyReLU(alpha=a))\n",
    "model.add(Conv2D(64, 2))\n",
    "model.add(LeakyReLU(alpha=a))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LeakyReLU(alpha=a))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "def fire(x, squeeze, expand):\n",
    "    x = Conv2D(squeeze, 1)(x)\n",
    "    x = LeakyReLU(alpha=a)(x)\n",
    "    e11 = Conv2D(expand, 1)(x)\n",
    "    e11 = LeakyReLU(alpha=a)(e11)\n",
    "    e33 = Conv2D(expand, 1)(x)\n",
    "    e33 = LeakyReLU(alpha=a)(e33)\n",
    "    return Concatenate(axis=3)([e11, e33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS))\n",
    "x = Conv2D(32, kernel_size=3, strides=2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS))(inputs)\n",
    "x = LeakyReLU(alpha=a)(x)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "x = fire(x, squeeze=8, expand=16)\n",
    "x = fire(x, squeeze=8, expand=16)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "'''x = fire(x, squeeze=32, expand=128)\n",
    "x = fire(x, squeeze=32, expand=128)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "x = fire(x, squeeze=48, expand=192)\n",
    "x = fire(x, squeeze=48, expand=192)\n",
    "x = fire(x, squeeze=64, expand=256)\n",
    "x = fire(x, squeeze=64, expand=256)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)'''\n",
    "x = Flatten()(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, 2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "model.add(LeakyReLU(alpha=a))\n",
    "model.add(Conv2D(32, 2))\n",
    "model.add(LeakyReLU(alpha=a))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, 2))\n",
    "model.add(LeakyReLU(alpha=a))\n",
    "model.add(Conv2D(64, 2))\n",
    "model.add(LeakyReLU(alpha=a))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(2, 1))\n",
    "model.add(Conv2DTranspose(1, kernel_size=IMG_PATCH_SIZE - 1, padding='valid'))\n",
    "#model.add(Reshape((-1, IMG_PATCH_SIZE * IMG_PATCH_SIZE)))\n",
    "#model.add(Permute((2,1)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.input_shape,layer.output_shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "DECAY = 0.00000\n",
    "adam = Adam(lr=LR, decay=DECAY)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "\n",
    "model.fit(train_d, train_l, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(train_data, train_labels)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
