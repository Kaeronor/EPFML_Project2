{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os,sys\n",
    "import gc\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import timeit\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the files for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 400, 400, 3) (100, 400, 400)\n"
     ]
    }
   ],
   "source": [
    "# Directory and files name\n",
    "train_dir = \"training/\"\n",
    "tr_image_dir = train_dir + \"images/\"\n",
    "tr_label_dir = train_dir + \"groundtruth/\"\n",
    "\n",
    "tr_image_files = os.listdir(tr_image_dir)\n",
    "tr_label_files = os.listdir(tr_label_dir)\n",
    "\n",
    "# Number of training samples\n",
    "N = len(tr_image_files)\n",
    "\n",
    "# Load the images and ground truth\n",
    "img_train = []\n",
    "label_train = []\n",
    "for i in range(N):\n",
    "    img = mpimg.imread(tr_image_dir + tr_image_files[i])\n",
    "    label = mpimg.imread(tr_label_dir + tr_label_files[i])\n",
    "    \n",
    "    img_train.append(img)\n",
    "    label_train.append(label)\n",
    "\n",
    "# Keep only sub-set of images\n",
    "NUM_IMAGES = N\n",
    "\n",
    "img_train = np.asarray(img_train[:NUM_IMAGES])\n",
    "label_train = np.asarray(label_train[:NUM_IMAGES])\n",
    "\n",
    "print(img_train.shape, label_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "label_patches = [img_crop(label_train[i, :, :], PATCH_SIZE, PATCH_SIZE) for i in range(NUM_IMAGES)]\n",
    "label_train =  np.asarray([label_patches[i][j] for i in range(len(label_patches)) for j in range(len(label_patches[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features for each image patch\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "def value_to_class(v):\n",
    "    df = np.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "label_train = [value_to_class(np.mean(label_train[i])) for i in range(len(label_train))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance the training dataset w/ sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 400\n",
    "WINDOW_SIZE = 52 # 18px - PATCH_SIZE - 18px\n",
    "NB_WINDOWS = (IMG_SIZE/PATCH_SIZE)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mirror_boundary_conditions(coord, dim):\n",
    "    \"\"\"\n",
    "    Return the correct coordinate according to mirror boundary conditions\n",
    "        coord: a coordinate (x or y) in the image\n",
    "        dim: the length of the axis of said coordinate\n",
    "    \"\"\"\n",
    "    # If the coordinate is outside of the bounds of the axis, take its reflection inside the image\n",
    "    if coord < 0:\n",
    "        coord = -coord\n",
    "    elif coord >= dim:\n",
    "        coord =  2*(dim-1) - coord % (2*(dim-1))\n",
    "    # Else, do nothing\n",
    "    return int(coord)\n",
    "\n",
    "def get_window(image, window_size, corner_coordinates, patch_size):\n",
    "    \"\"\"\n",
    "    Get a window in image, centered on a patch, taking into account boundary conditions\n",
    "        image: a numpy array representing our image\n",
    "        window_size: an even number specifying the size of the window\n",
    "        corner_coordinates: a list containing the x-y coordinates of the patch's upleft pixel\n",
    "        path_size: an even number specifying the size of the central patch\n",
    "    \"\"\"\n",
    "    # Get convenient variables\n",
    "    window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    nrows, ncols, nchannels = image.shape\n",
    "    window = np.zeros((window_size, window_size, nchannels))\n",
    "    \n",
    "    # Fill in the window array with pixels of the image\n",
    "    for i in range(window_size):\n",
    "        # Apply mirror boundary conditions on the x-coordinate\n",
    "        i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i, nrows)\n",
    "        for j in range(window_size):\n",
    "            # Same for the y-coordinate\n",
    "            j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j, ncols)\n",
    "            # Fill in the window with the corresponding pixel\n",
    "            window[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_to_the_right(image, window, corner_coordinates, patch_size):\n",
    "    nrows, ncols, _ = image.shape\n",
    "    window_size = len(window)\n",
    "    #window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    step = patch_size\n",
    "    \n",
    "    shifted = np.roll(window, -step, axis=1)\n",
    "    for i in range(window_size):\n",
    "        i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i, nrows)            \n",
    "        for j in range(window_size-step, window_size):\n",
    "            j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j + step, ncols)\n",
    "            shifted[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return shifted\n",
    "\n",
    "def shift_to_the_bottom(image, window, corner_coordinates, patch_size):\n",
    "    nrows, ncols, _ = image.shape\n",
    "    window_size = len(window)\n",
    "    #window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    step = patch_size\n",
    "    \n",
    "    shifted = np.roll(window, -step, axis=0)\n",
    "    for j in range(window_size):\n",
    "        j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j, ncols)\n",
    "        for i in range(window_size-step, window_size):\n",
    "            i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i + step, nrows)\n",
    "            shifted[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return shifted\n",
    "\n",
    "def sliding_window(image, window_size, patch_size):\n",
    "    \"\"\"\n",
    "    Construct a list of sliding windows of given size on an image.\n",
    "    The windows, centered on a patch, will slide from left to right and from up to down.\n",
    "        image: a numpy array representing our image\n",
    "        window_size: an even number specifying the size of the window\n",
    "        patch_size: the size of the central patch\n",
    "    \"\"\"\n",
    "    nrows, ncols, _ = image.shape\n",
    "    windows = []\n",
    "    i = 0\n",
    "    row_windows = [get_window(image, window_size, [i, 0], patch_size)]\n",
    "    for j in range(patch_size, ncols-1, patch_size):\n",
    "        #print(j)\n",
    "        row_windows += [shift_to_the_right(image, row_windows[-1], [i, j], patch_size)]\n",
    "    windows += row_windows\n",
    "    #print('===')\n",
    "    for i in range(patch_size, nrows-1, patch_size):\n",
    "        #print(i)\n",
    "        row_windows = [shift_to_the_bottom(image, row_windows[int(j/patch_size)], [i, j], patch_size) \n",
    "                       for j in range(0, ncols-1, patch_size)]\n",
    "        #print(len(row_windows))\n",
    "        windows += row_windows\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance(train_data):\n",
    "    #print(len(train_data), train_data[0].shape)\n",
    "    data_copy = list(train_data)\n",
    "    \n",
    "    train_data += [np.rot90(im) for im in data_copy]\n",
    "    train_data += [np.rot90(im, k=2) for im in data_copy]\n",
    "    train_data += [np.rot90(im, k=3) for im in data_copy]\n",
    "    train_data += [np.fliplr(im) for im in data_copy]\n",
    "    train_data += [np.flipud(im) for im in data_copy]\n",
    "    train_data += [np.transpose(im, (1,0,2)) for im in data_copy]\n",
    "    \n",
    "    del data_copy\n",
    "    gc.collect()\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(img_train, train_labels, window_size, patch_size):\n",
    "    train_data = []\n",
    "    nb_windows = (IMG_SIZE/patch_size)**2\n",
    "    for im in img_train:\n",
    "        w_im = enhance(sliding_window(im, window_size, patch_size))\n",
    "        #w_labels = sliding_window(labels[:, :, np.newaxis], window_size, step)\n",
    "        train_data += w_im\n",
    "        #train_labels += w_labels\n",
    "        #path = './windows_train_patch/' + str(i)\n",
    "        #os.makedirs(path, exist_ok=True)\n",
    "        #for wi, j in zip(w_im, range(len(w_im))):\n",
    "            #img_name = path + '/im_' + str(j) + '.png'\n",
    "            #plt.imsave(img_name, wi)\n",
    "            #label_name = path + '/label_' + str(j) + '.png'\n",
    "            #plt.imsave(label_name, wl[:,:,0])\n",
    "    train_labels *= 7\n",
    "    \n",
    "    return np.asarray(train_data).reshape((len(train_labels), window_size, window_size, 3)), np.asarray(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_train, label_train = compute(img_train, label_train, WINDOW_SIZE, PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#a = np.array(range(10*10))\n",
    "#a = a.reshape((10, 10))\n",
    "#print(a)\n",
    "#aa = get_window(a[:,:,np.newaxis], 5, [5,5])[:,:,0]\n",
    "#print('\\n')\n",
    "#print(aa)\n",
    "#print('\\n')\n",
    "#print(shift_to_the_bottom(a[:,:,np.newaxis], aa[:,:,np.newaxis], [5,5], 2)[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "#IMG_PATCH_SIZE = 52\n",
    "#TRAINING_SIZE = 62500\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 15\n",
    "a = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LeakyReLU, Input, Reshape, Permute, Average\n",
    "from keras.layers import Conv2D, MaxPooling2D, Concatenate, Lambda, Activation, GlobalAveragePooling2D, Conv2DTranspose, GlobalAveragePooling1D\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model0(IMG_PATCH_SIZE, TRAINING_SIZE):\n",
    "    model0 = Sequential()\n",
    "    model0.add(Conv2D(32, 2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(Conv2D(32, 2))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model0.add(Dropout(0.25))\n",
    "\n",
    "    model0.add(Conv2D(64, 2))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(Conv2D(64, 2))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model0.add(Dropout(0.25))\n",
    "\n",
    "    model0.add(Flatten())\n",
    "    model0.add(Dense(128))\n",
    "    model0.add(Dropout(0.5))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "def fire(x, squeeze, expand):\n",
    "    x = Conv2D(squeeze, 1)(x)\n",
    "    x = LeakyReLU(alpha=a)(x)\n",
    "    e11 = Conv2D(expand, 1)(x)\n",
    "    e11 = LeakyReLU(alpha=a)(e11)\n",
    "    e33 = Conv2D(expand, 1)(x)\n",
    "    e33 = LeakyReLU(alpha=a)(e33)\n",
    "    return Concatenate(axis=3)([e11, e33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(IMG_PATCH_SIZE, TRAINING_SIZE):\n",
    "    inputs = Input(shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS))\n",
    "    x = Conv2D(32, kernel_size=3, strides=2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS))(inputs)\n",
    "    x = LeakyReLU(alpha=a)(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    x = fire(x, squeeze=8, expand=16)\n",
    "    x = fire(x, squeeze=8, expand=16)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    '''x = fire(x, squeeze=32, expand=128)\n",
    "    x = fire(x, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    x = fire(x, squeeze=48, expand=192)\n",
    "    x = fire(x, squeeze=48, expand=192)\n",
    "    x = fire(x, squeeze=64, expand=256)\n",
    "    x = fire(x, squeeze=64, expand=256)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)'''\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model1 = Model(inputs, x)\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(IMG_PATCH_SIZE, TRAINING_SIZE):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(32, 2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(Conv2D(32, 2))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Dropout(0.25))\n",
    "\n",
    "    model2.add(Conv2D(64, 2))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(Conv2D(64, 2))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Dropout(0.25))\n",
    "\n",
    "    model2.add(Conv2D(2, 1))\n",
    "    model2.add(Conv2DTranspose(1, kernel_size=IMG_PATCH_SIZE - 1, padding='valid'))\n",
    "    #model.add(Reshape((-1, IMG_PATCH_SIZE * IMG_PATCH_SIZE)))\n",
    "    #model.add(Permute((2,1)))\n",
    "    model2.add(GlobalAveragePooling2D())\n",
    "    model2.add(Activation('sigmoid'))\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in model.layers:\n",
    "    #print(layer.input_shape,layer.output_shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_window_size = np.nan\n",
    "best_model = np.nan\n",
    "best_score = 0\n",
    "\n",
    "LR = 0.001\n",
    "DECAY = 0.00000\n",
    "adam = Adam(lr=LR, decay=DECAY)\n",
    "\n",
    "for window_size in range(30, 60, 2):\n",
    "    imgs, labels = compute(img_train, label_train, window_size, PATCH_SIZE)\n",
    "    training_size = imgs.shape[0]\n",
    "    num_model = 0\n",
    "    for model in [model0(window_size, training_size)]:#, model1(window_size, training_size), model2(window_size, training_size)]:\n",
    "        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[f1])\n",
    "        model.fit(imgs, labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS)\n",
    "        score = model.evaluate(train, labels)[1]\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = num_model\n",
    "            best_window_size = window_size\n",
    "        num_model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "DECAY = 0.00000\n",
    "adam = Adam(lr=LR, decay=DECAY)\n",
    "\n",
    "#model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "\n",
    "#model.fit(img_train, label_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = model.evaluate(train_data, train_labels)\n",
    "#score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
