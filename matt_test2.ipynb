{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os,sys\n",
    "import gc\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import timeit\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the files for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 400, 400, 3) (2, 400, 400)\n"
     ]
    }
   ],
   "source": [
    "# Directory and files name\n",
    "train_dir = \"training/\"\n",
    "tr_image_dir = train_dir + \"images/\"\n",
    "tr_label_dir = train_dir + \"groundtruth/\"\n",
    "\n",
    "tr_image_files = os.listdir(tr_image_dir)\n",
    "tr_label_files = os.listdir(tr_label_dir)\n",
    "\n",
    "# Number of training samples\n",
    "N = len(tr_image_files)\n",
    "\n",
    "# Load the images and ground truth\n",
    "img_train = []\n",
    "label_train = []\n",
    "for i in range(N):\n",
    "    img = mpimg.imread(tr_image_dir + tr_image_files[i])\n",
    "    label = mpimg.imread(tr_label_dir + tr_label_files[i])\n",
    "    \n",
    "    img_train.append(img)\n",
    "    label_train.append(label)\n",
    "\n",
    "# Keep only sub-set of images\n",
    "NUM_IMAGES = 2\n",
    "\n",
    "img_train = np.asarray(img_train[:NUM_IMAGES])\n",
    "label_train = np.asarray(label_train[:NUM_IMAGES])\n",
    "\n",
    "print(img_train.shape, label_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "label_patches = [img_crop(label_train[i, :, :], PATCH_SIZE, PATCH_SIZE) for i in range(NUM_IMAGES)]\n",
    "label_train =  np.asarray([label_patches[i][j] for i in range(len(label_patches)) for j in range(len(label_patches[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features for each image patch\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "def value_to_class(v):\n",
    "    df = np.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "label_train = [value_to_class(np.mean(label_train[i])) for i in range(len(label_train))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance the training dataset w/ sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 400\n",
    "WINDOW_SIZE = 52 # 18px - PATCH_SIZE - 18px\n",
    "NB_WINDOWS = (IMG_SIZE/PATCH_SIZE)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mirror_boundary_conditions(coord, dim):\n",
    "    \"\"\"\n",
    "    Return the correct coordinate according to mirror boundary conditions\n",
    "        coord: a coordinate (x or y) in the image\n",
    "        dim: the length of the axis of said coordinate\n",
    "    \"\"\"\n",
    "    # If the coordinate is outside of the bounds of the axis, take its reflection inside the image\n",
    "    if coord < 0:\n",
    "        coord = -coord\n",
    "    elif coord >= dim:\n",
    "        coord =  2*(dim-1) - coord % (2*(dim-1))\n",
    "    # Else, do nothing\n",
    "    return int(coord)\n",
    "\n",
    "def get_window(image, window_size, corner_coordinates, patch_size):\n",
    "    \"\"\"\n",
    "    Get a window in image, centered on a patch, taking into account boundary conditions\n",
    "        image: a numpy array representing our image\n",
    "        window_size: an even number specifying the size of the window\n",
    "        corner_coordinates: a list containing the x-y coordinates of the patch's upleft pixel\n",
    "        path_size: an even number specifying the size of the central patch\n",
    "    \"\"\"\n",
    "    # Get convenient variables\n",
    "    window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    nrows, ncols, nchannels = image.shape\n",
    "    window = np.zeros((window_size, window_size, nchannels))\n",
    "    \n",
    "    # Fill in the window array with pixels of the image\n",
    "    for i in range(window_size):\n",
    "        # Apply mirror boundary conditions on the x-coordinate\n",
    "        i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i, nrows)\n",
    "        for j in range(window_size):\n",
    "            # Same for the y-coordinate\n",
    "            j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j, ncols)\n",
    "            # Fill in the window with the corresponding pixel\n",
    "            window[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_to_the_right(image, window, corner_coordinates, patch_size):\n",
    "    nrows, ncols, _ = image.shape\n",
    "    window_size = len(window)\n",
    "    #window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    step = patch_size\n",
    "    \n",
    "    shifted = np.roll(window, -step, axis=1)\n",
    "    for i in range(window_size):\n",
    "        i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i, nrows)            \n",
    "        for j in range(window_size-step, window_size):\n",
    "            j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j + step, ncols)\n",
    "            shifted[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return shifted\n",
    "\n",
    "def shift_to_the_bottom(image, window, corner_coordinates, patch_size):\n",
    "    nrows, ncols, _ = image.shape\n",
    "    window_size = len(window)\n",
    "    #window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    step = patch_size\n",
    "    \n",
    "    shifted = np.roll(window, -step, axis=0)\n",
    "    for j in range(window_size):\n",
    "        j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j, ncols)\n",
    "        for i in range(window_size-step, window_size):\n",
    "            i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i + step, nrows)\n",
    "            shifted[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return shifted\n",
    "\n",
    "def sliding_window(image, window_size, patch_size):\n",
    "    \"\"\"\n",
    "    Construct a list of sliding windows of given size on an image.\n",
    "    The windows, centered on a patch, will slide from left to right and from up to down.\n",
    "        image: a numpy array representing our image\n",
    "        window_size: an even number specifying the size of the window\n",
    "        patch_size: the size of the central patch\n",
    "    \"\"\"\n",
    "    nrows, ncols, _ = image.shape\n",
    "    windows = []\n",
    "    i = 0\n",
    "    row_windows = [get_window(image, window_size, [i, 0], patch_size)]\n",
    "    for j in range(patch_size, ncols-1, patch_size):\n",
    "        #print(j)\n",
    "        row_windows += [shift_to_the_right(image, row_windows[-1], [i, j], patch_size)]\n",
    "    windows += row_windows\n",
    "    #print('===')\n",
    "    for i in range(patch_size, nrows-1, patch_size):\n",
    "        #print(i)\n",
    "        row_windows = [shift_to_the_bottom(image, row_windows[int(j/patch_size)], [i, j], patch_size) \n",
    "                       for j in range(0, ncols-1, patch_size)]\n",
    "        #print(len(row_windows))\n",
    "        windows += row_windows\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance(train_data):\n",
    "    #print(len(train_data), train_data[0].shape)\n",
    "    data_copy = list(train_data)\n",
    "    \n",
    "    train_data += [np.rot90(im) for im in data_copy]\n",
    "    train_data += [np.rot90(im, k=2) for im in data_copy]\n",
    "    train_data += [np.rot90(im, k=3) for im in data_copy]\n",
    "    train_data += [np.fliplr(im) for im in data_copy]\n",
    "    train_data += [np.flipud(im) for im in data_copy]\n",
    "    train_data += [np.transpose(im, (1,0,2)) for im in data_copy]\n",
    "    \n",
    "    del data_copy\n",
    "    gc.collect()\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(img_train, train_labels, window_size, patch_size):\n",
    "    train_data = []\n",
    "    nb_windows = (IMG_SIZE/patch_size)**2\n",
    "    i = 0\n",
    "    for im in img_train:\n",
    "        print(i)\n",
    "        #w_im = enhance(sliding_window(im, window_size, patch_size))\n",
    "        w_im = sliding_window(im, window_size, patch_size)\n",
    "        #w_labels = sliding_window(labels[:, :, np.newaxis], window_size, step)\n",
    "        train_data += w_im\n",
    "        i += 1\n",
    "        #train_labels += w_labels\n",
    "        #path = './windows_train_patch/' + str(i)\n",
    "        #os.makedirs(path, exist_ok=True)\n",
    "        #for wi, j in zip(w_im, range(len(w_im))):\n",
    "            #img_name = path + '/im_' + str(j) + '.png'\n",
    "            #plt.imsave(img_name, wi)\n",
    "            #label_name = path + '/label_' + str(j) + '.png'\n",
    "            #plt.imsave(label_name, wl[:,:,0])\n",
    "    #train_labels *= 7\n",
    "    \n",
    "    return np.asarray(train_data).reshape((len(train_labels), window_size, window_size, 3)), np.asarray(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_train, label_train = compute(img_train, label_train, WINDOW_SIZE, PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#a = np.array(range(10*10))\n",
    "#a = a.reshape((10, 10))\n",
    "#print(a)\n",
    "#aa = get_window(a[:,:,np.newaxis], 5, [5,5])[:,:,0]\n",
    "#print('\\n')\n",
    "#print(aa)\n",
    "#print('\\n')\n",
    "#print(shift_to_the_bottom(a[:,:,np.newaxis], aa[:,:,np.newaxis], [5,5], 2)[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "#IMG_PATCH_SIZE = 52\n",
    "#TRAINING_SIZE = 62500\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 15\n",
    "a = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LeakyReLU, Input, Reshape, Permute, Average\n",
    "from keras.layers import Conv2D, MaxPooling2D, Concatenate, Lambda, Activation, GlobalAveragePooling2D, Conv2DTranspose, GlobalAveragePooling1D\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model0(IMG_PATCH_SIZE, TRAINING_SIZE):\n",
    "    model0 = Sequential()\n",
    "    model0.add(Conv2D(32, 2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(Conv2D(32, 2))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model0.add(Dropout(0.25))\n",
    "\n",
    "    model0.add(Conv2D(64, 2))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(Conv2D(64, 2))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model0.add(Dropout(0.25))\n",
    "\n",
    "    model0.add(Flatten())\n",
    "    model0.add(Dense(128))\n",
    "    model0.add(Dropout(0.5))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "def fire(x, squeeze, expand):\n",
    "    x = Conv2D(squeeze, 1)(x)\n",
    "    x = LeakyReLU(alpha=a)(x)\n",
    "    e11 = Conv2D(expand, 1)(x)\n",
    "    e11 = LeakyReLU(alpha=a)(e11)\n",
    "    e33 = Conv2D(expand, 1)(x)\n",
    "    e33 = LeakyReLU(alpha=a)(e33)\n",
    "    return Concatenate(axis=3)([e11, e33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(IMG_PATCH_SIZE, TRAINING_SIZE):\n",
    "    inputs = Input(shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS))\n",
    "    x = Conv2D(32, kernel_size=3, strides=2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS))(inputs)\n",
    "    x = LeakyReLU(alpha=a)(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    x = fire(x, squeeze=8, expand=16)\n",
    "    x = fire(x, squeeze=8, expand=16)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    '''x = fire(x, squeeze=32, expand=128)\n",
    "    x = fire(x, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    x = fire(x, squeeze=48, expand=192)\n",
    "    x = fire(x, squeeze=48, expand=192)\n",
    "    x = fire(x, squeeze=64, expand=256)\n",
    "    x = fire(x, squeeze=64, expand=256)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)'''\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model1 = Model(inputs, x)\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(IMG_PATCH_SIZE, TRAINING_SIZE):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(32, 2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(Conv2D(32, 2))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Dropout(0.25))\n",
    "\n",
    "    model2.add(Conv2D(64, 2))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(Conv2D(64, 2))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Dropout(0.25))\n",
    "\n",
    "    model2.add(Conv2D(2, 1))\n",
    "    model2.add(Conv2DTranspose(1, kernel_size=IMG_PATCH_SIZE - 1, padding='valid'))\n",
    "    #model.add(Reshape((-1, IMG_PATCH_SIZE * IMG_PATCH_SIZE)))\n",
    "    #model.add(Permute((2,1)))\n",
    "    model2.add(GlobalAveragePooling2D())\n",
    "    model2.add(Activation('sigmoid'))\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in model.layers:\n",
    "    #print(layer.input_shape,layer.output_shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_window_size = np.nan\n",
    "best_model = np.nan\n",
    "best_score = 0\n",
    "\n",
    "LR = 0.001\n",
    "DECAY = 0.00000\n",
    "adam = Adam(lr=LR, decay=DECAY)\n",
    "\n",
    "for window_size in range(30, 60, 2):\n",
    "    imgs, labels = compute(img_train, label_train, window_size, PATCH_SIZE)\n",
    "    training_size = imgs.shape[0]\n",
    "    num_model = 0\n",
    "    for model in [model0(window_size, training_size)]:#, model1(window_size, training_size), model2(window_size, training_size)]:\n",
    "        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[f1])\n",
    "        model.fit(imgs, labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS)\n",
    "        score = model.evaluate(train, labels)[1]\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = num_model\n",
    "            best_window_size = window_size\n",
    "        num_model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MATT\\Anaconda3\\lib\\site-packages\\keras\\models.py:288: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "path = 'FCN_W32_noenh.h5'\n",
    "model = keras.models.load_model(path)\n",
    "imgs, labels = compute(img_train, label_train, 32, PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24ea2759588>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAC4pJREFUeJzt3U+IXeUdxvHnaRoT/AcJNiGNabUS\ni1noWIYoWEpENNFNdCHoomQhjAsFBTfBjW4KbtR2IUKsIVn4B0GtWUhjCEJaKNZRYoykTURSExMy\n1SyUitHor4s5A2MyM/fMvefcc878vh8Y7r1nztzzyzv3yXvufd95jyNCAPL5SdMFAGgG4QeSIvxA\nUoQfSIrwA0kRfiApwg8kRfiBpAg/kNRPh3mwC7wkluqigZ7j6mu/rqia3g4fuHBoxxpUmXbp0r+n\nTbrUtt/of/o2zrjMvh5keq/tTZL+JGmRpD9HxBNz7X+pl8cNvqXv40nS7hP7B/r5+dj485GhHWtQ\nZdqlS/+eNulS274Te/VlnC4V/r5P+20vkvSMpNslrZN0r+11/T4fgOEa5D3/ekkfR8QnEfGtpJcl\nba6mLAB1GyT8qyUdm/b4eLENQAcM8oHfTO8rzvsAwfaYpDFJWqp2fCgCYLCe/7ikNdMeXy7pxLk7\nRcS2iBiNiNHFWjLA4QBUaZDwvytpre0rbV8g6R5Ju6opC0Dd+j7tj4izth+UtFuTQ33bI+KjyioD\nUKuBxvnnq4px/jK6NC5blarmP7SlXTL+Dsvo1S7rNx7T+Aff1DvOD6DbCD+QFOEHkiL8QFKEH0iK\n8ANJEX4gqaEu5lFGFePVZcZ/F9o4clW19mqXYbVJl9pe6ubriZ4fSIrwA0kRfiApwg8kRfiBpAg/\nkBThB5Ii/EBSrZvk07aJEAvJMC94gvMNYwLb4fii9HPR8wNJEX4gKcIPJEX4gaQIP5AU4QeSIvxA\nUoQfSKp1k3xQnypWOOriijVdMsy2o+cHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSGmiG\nn+2jkr6S9L2ksxExWkVRAOpXxfTemyPi8wqeB8AQcdoPJDVo+EPSW7bfsz020w62x2yP2x7/TmcG\nPByAqgx62n9TRJywvULSHtv/ioh903eIiG2StknSpV4eAx4PQEUG6vkj4kRxOyHpdUnrqygKQP36\nDr/ti2xfMnVf0m2SDlZVGIB6DXLav1LS67annufFiPhrJVWhMb0Wk+CqP/1r2yInfYc/Ij6RdF2F\ntQAYIob6gKQIP5AU4QeSIvxAUoQfSIrwA0kRfiAprtiDH2EST33adrUjen4gKcIPJEX4gaQIP5AU\n4QeSIvxAUoQfSIrwA0kxyQfzUmYSSpsmCrVp9Zw21SLR8wNpEX4gKcIPJEX4gaQIP5AU4QeSIvxA\nUkMd57/62q+1e/fcY8BtGwvNhvY/X1XzFljMA0ArEH4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSMoR\nMbSDXerlcYNvqf04bVpMooyFNrGma+2/kKzfeEzjH3zjMvv27Pltb7c9YfvgtG3Lbe+xfaS4XTZI\nwQCGr8xp/w5Jm87ZtlXS3ohYK2lv8RhAh/QMf0Tsk3T6nM2bJe0s7u+UdGfFdQGoWb8f+K2MiJOS\nVNyuqK4kAMNQ+1/12R6TNCZJS3Vh3YcDUFK/Pf8p26skqbidmG3HiNgWEaMRMbpYS/o8HICq9Rv+\nXZK2FPe3SHqjmnIADEuZob6XJP1D0q9tH7d9n6QnJN1q+4ikW4vHADpkqJN8Rq9bGv/cvWZoxwOy\nqXSSD4CFifADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeS\nIvxAUrUv4Fm1qq5uU+aqMgvtSjrDUsUVe9rU9m26AlGvdjkcX5R+Lnp+ICnCDyRF+IGkCD+QFOEH\nkiL8QFKEH0iK8ANJDXWSz+EDF7Zq8gbqUeZ33GviTJcm1kjdnDRGzw8kRfiBpAg/kBThB5Ii/EBS\nhB9IivADSRF+IKnOreSDevWarFLVRJU2TXgZ1oSitk0E6tnz295ue8L2wWnbHrf9me39xdcd9ZYJ\noGplTvt3SNo0w/anI2Kk+Hqz2rIA1K1n+CNin6TTQ6gFwBAN8oHfg7YPFG8Lls22k+0x2+O2x7/T\nmQEOB6BK/Yb/WUlXSRqRdFLSk7PtGBHbImI0IkYXa0mfhwNQtb7CHxGnIuL7iPhB0nOS1ldbFoC6\n9RV+26umPbxL0sHZ9gXQTj3H+W2/JGmDpMtsH5f0mKQNtkckhaSjku6vsUYANegZ/oi4d4bNz9dQ\nCzqgbRNVqtCr3jatKlQlpvcCSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFIs5jGHYS1sgXar6oo9bUPP\nDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKSb5LBBVLbKRdWGLjOj5gaQIP5AU4QeSIvxAUoQf\nSIrwA0kRfiApwg8k1bpJPqye05+FutoM6kPPDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJtW6cn3H8\n7qtqYRHUq2fPb3uN7bdtH7L9ke2Hiu3Lbe+xfaS4XVZ/uQCqUua0/6ykRyLiGkk3SnrA9jpJWyXt\njYi1kvYWjwF0RM/wR8TJiHi/uP+VpEOSVkvaLGlnsdtOSXfWVSSA6s3rAz/bV0i6XtI7klZGxElp\n8j8ISSuqLg5AfUqH3/bFkl6V9HBEfDmPnxuzPW57/Dud6adGADUoFX7bizUZ/Bci4rVi8ynbq4rv\nr5I0MdPPRsS2iBiNiNHFWlJFzQAqUObTfkt6XtKhiHhq2rd2SdpS3N8i6Y3qywNQlzLj/DdJ+r2k\nD21PDeA+KukJSa/Yvk/Sp5LurqdEAHXoGf6I+Lskz/LtW6otJycWMMGUYb4WmN4LJEX4gaQIP5AU\n4QeSIvxAUoQfSIrwA0kRfiCp1q3kk1GXJvF0qdYuGmb70vMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8\nQFKEH0iKST6JlJlAUuZSW+hPFRN4ev1+1m/8uvRz0fMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFJp\nx/kzLkrBGH739XrdHo4vSj8XPT+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQcEcM7mP1fSf+Z\ntukySZ8PrYDBdaneLtUqdaveNtf6y4j4WZkdhxr+8w5uj0fEaGMFzFOX6u1SrVK36u1SrXPhtB9I\nivADSTUd/m0NH3++ulRvl2qVulVvl2qdVaPv+QE0p+meH0BDGgu/7U22/237Y9tbm6qjDNtHbX9o\ne7/t8abrOZft7bYnbB+ctm257T22jxS3y5qscbpZ6n3c9mdFG++3fUeTNU6xvcb227YP2f7I9kPF\n9ta2b1mNhN/2IknPSLpd0jpJ99pe10Qt83BzRIy0dIhnh6RN52zbKmlvRKyVtLd43BY7dH69kvR0\n0cYjEfHmkGuazVlJj0TENZJulPRA8Vptc/uW0lTPv17SxxHxSUR8K+llSZsbqqXzImKfpNPnbN4s\naWdxf6ekO4da1BxmqbeVIuJkRLxf3P9K0iFJq9Xi9i2rqfCvlnRs2uPjxba2Cklv2X7P9ljTxZS0\nMiJOSpMvYEkrGq6njAdtHyjeFrTuNNr2FZKul/SOutm+P9JU+D3DtjYPO9wUEb/R5NuUB2z/rumC\nFqBnJV0laUTSSUlPNlvOj9m+WNKrkh6OiC+brqcKTYX/uKQ10x5fLulEQ7X0FBEnitsJSa9r8m1L\n252yvUqSituJhuuZU0SciojvI+IHSc+pRW1se7Emg/9CRLxWbO5U+86kqfC/K2mt7SttXyDpHkm7\nGqplTrYvsn3J1H1Jt0k6OPdPtcIuSVuK+1skvdFgLT1NBalwl1rSxrYt6XlJhyLiqWnf6lT7zqSx\nST7FUM4fJS2StD0i/tBIIT3Y/pUme3tpcqnzF9tWq+2XJG3Q5F+bnZL0mKS/SHpF0i8kfSrp7oho\nxYdss9S7QZOn/CHpqKT7p95TN8n2byX9TdKHkn4oNj+qyff9rWzfspjhByTFDD8gKcIPJEX4gaQI\nP5AU4QeSIvxAUoQfSIrwA0n9H97uARluMJMxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24e9ebc6908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_0 = predictions[:625]\n",
    "test = predict_0.reshape((25, 25))\n",
    "test[test < 0.25] = 0\n",
    "test[test > 0] = 1\n",
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24ea2c48780>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANJEX4gKcIPJEX4gaQIP5AU4QeS+j+NZgIVJuF86AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24e9e6dc6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# find connected components\n",
    "labeled, nr_objects = ndimage.label(test > threshold) \n",
    "print(nr_objects)\n",
    "\n",
    "plt.imshow(labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 1, 1, 2, 2, 150, 11, 1, 22, 1, 1, 1, 1]\n",
      "[ 0  1  2  3  4  5  8 10 11 12 13]\n"
     ]
    }
   ],
   "source": [
    "areas = [len(np.where(labeled == i)[0]) for i in range(1, nr_objects+1)]\n",
    "print(areas)\n",
    "thresh_size = 4\n",
    "smallest = np.where(np.array(areas) <= thresh_size)[0]\n",
    "print(smallest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in smallest:\n",
    "    labeled[np.where(labeled == i+1)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24ea3cf1128>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAACypJREFUeJzt3U+IHvUdx/HPp+maYLSQYBPSJK22\npMVcupZtKlhKJGijl+hBMIeSg7AWFBS8BC96KXhR24NYYg3JwT8Ias0hVMMipIUirhI0krYRSXVN\nyFY8KIXGJH572Ak8ibv7zD7PzDMz+b5fsDzzzDO782Wyn/xmnvnu73FECEA+32q6AADNIPxAUoQf\nSIrwA0kRfiApwg8kRfiBpAg/kBThB5L69ih3doWXxwqtHOUugVT+p//qqzjjMtsOFX7b2yX9QdIy\nSX+KiMcW236FVuoX3jbMLgEs4q2YKr3twKf9tpdJekrSbZI2S9ppe/OgPw/AaA1zzb9F0ocR8VFE\nfCXpRUk7qikLQN2GCf96SZ/0PJ8p1gHogGGu+ed7U+Ebfx9se1LSpCSt0JVD7A5AlYYZ+Wckbex5\nvkHSyUs3iog9ETERERNjWj7E7gBUaZjwvy1pk+3rbF8h6W5JB6opC0DdBj7tj4hztu+X9LrmbvXt\njYgPKqsMQK2Gus8fEQclHayoFgAjRHsvkBThB5Ii/EBShB9IivADSRF+ICnCDyQ10sk8WmVqQ/9t\nts3UX0fL/PzI+UVff3t82Ygq6ZgO/j4x8gNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSCpvk09C\n/Rp4ULMyjUD9VNgoxMgPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApmnwSKTMLT79GoDKNQsz2\nM4QRzvbDyA8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyQ1VIef7ROSvpR0XtK5iJiooigA\n9auivffmiPisgp8DYIQ47QeSGjb8IekN2+/YnpxvA9uTtqdtT5/VmSF3B6Aqw5723xQRJ22vkXTI\n9j8i4nDvBhGxR9IeSfqOV8eQ+wNQkaFG/og4WTzOSnpV0pYqigJQv4HDb3ul7asvLEu6VdLRqgoD\nUK9hTvvXSnrV9oWf83xE/KWSqtCYfhNx8Kk/QxjhRB1lDBz+iPhI0k8rrAXACHGrD0iK8ANJEX4g\nKcIPJEX4gaQIP5AU4QeS4hN7cBGaeGo0taH/NnxiD4C6EX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQf\nSIomHyxJv5l+JJVrZhmVNs2e06ZaxMgPpEX4gaQIP5AU4QeSIvxAUoQfSIrwA0lxnx8XKXUfP5uq\n+haYzANAGxB+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0jq8mzyGWVTRhVaNsnDZaVNE4uUMWy9vx0r\nvWnfkd/2Xtuzto/2rFtt+5Dt48XjqgFLBdCQMqf9+yRtv2TdbklTEbFJ0lTxHECH9A1/RByW9Pkl\nq3dI2l8s75d0R8V1AajZoG/4rY2IU5JUPK6priQAo1D7G362JyVNStIKXVn37gCUNOjIf9r2Okkq\nHmcX2jAi9kTERERMjGn5gLsDULVBw39A0q5ieZek16opB8ColLnV94Kkv0v6ie0Z2/dIekzSLbaP\nS7qleA6gQ/pe80fEzgVe2rbkvf14TPpjx5ouRqFrjSi4LNDeCyRF+IGkCD+QFOEHkiL8QFKEH0iK\n8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCp7n1iT1WfblNmAg0+SWcwVUxO0qZj\n36bJVvodlzhb+kcx8gNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSGq0TT7/Otuu5g3Uo8y/cb/G\nmS411kidbBpj5AeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kFT3ZvJBrV4/eWTR13/9vfFqdtSm\nhpdRNRS1rBGo78hve6/tWdtHe9Y9avtT20eKr9vrLRNA1cqc9u+TtH2e9U9GxHjxdbDasgDUrW/4\nI+KwpM9HUAuAERrmDb/7bb9XXBasWmgj25O2p21Pn9WZIXYHoEqDhv9pST+SNC7plKTHF9owIvZE\nxERETIxp+YC7A1C1gcIfEacj4nxEfC3pGUlbqi0LQN0GCr/tdT1P75R0dKFtAbRT3/v8tl+QtFXS\nNbZnJD0iaavtcUkh6YSke2usEUAN+oY/InbOs/rZGmpBB/RrApIqbAQalX6NNW2aVahCtPcCSRF+\nICnCDyRF+IGkCD+QFOEHkiL8QFJM5rGYfvd32zQhBepT1Sf2tAwjP5AU4QeSIvxAUoQfSIrwA0kR\nfiApwg8kRfiBpGjywUX6TcRRZjIPdAMjP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpGjySYQG\nHfRi5AeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpLjPj8qV6SfoN2kI6td35Le90fabto/Z/sD2A8X6\n1bYP2T5ePK6qv1wAVSlz2n9O0kMRcb2kGyXdZ3uzpN2SpiJik6Sp4jmAjugb/og4FRHvFstfSjom\nab2kHZL2F5vtl3RHXUUCqN6S3vCzfa2kGyS9JWltRJyS5v6DkLSm6uIA1Kd0+G1fJellSQ9GxBdL\n+L5J29O2p8/qzCA1AqhBqfDbHtNc8J+LiFeK1adtryteXydpdr7vjYg9ETERERNjWl5FzQAqUObd\nfkt6VtKxiHii56UDknYVy7skvVZ9eQDqUuY+/02SfiPpfdsXbuA+LOkxSS/ZvkfSx5LuqqdEAHXo\nG/6I+JskL/DytmrLAZKb2rD469tmKtsV7b1AUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5JiJh8s\nCTPw1KzCJp5+GPmBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRFk08iZRp0ynzUFgY0wgaeMhj5\ngaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCpvPf5W3bPdRS4h49ejPxAUoQfSIrwA0kRfiApwg8kRfiB\npAg/kBThB5JyRIxuZ/Z/JP27Z9U1kj4bWQHD61K9XapV6la9ba71BxHx3TIbjjT839i5PR0RE40V\nsERdqrdLtUrdqrdLtS6G034gKcIPJNV0+Pc0vP+l6lK9XapV6la9Xap1QY1e8wNoTtMjP4CGNBZ+\n29tt/9P2h7Z3N1VHGbZP2H7f9hHb003Xcynbe23P2j7as2617UO2jxePq5qssdcC9T5q+9PiGB+x\nfXuTNV5ge6PtN20fs/2B7QeK9a09vmU1En7byyQ9Jek2SZsl7bS9uYlaluDmiBhv6S2efZK2X7Ju\nt6SpiNgkaap43hb79M16JenJ4hiPR8TBEde0kHOSHoqI6yXdKOm+4ne1zce3lKZG/i2SPoyIjyLi\nK0kvStrRUC2dFxGHJX1+yeodkvYXy/sl3THSohaxQL2tFBGnIuLdYvlLScckrVeLj29ZTYV/vaRP\nep7PFOvaKiS9Yfsd25NNF1PS2og4Jc39Akta03A9Zdxv+73isqB1p9G2r5V0g6S31M3je5Gmwu95\n1rX5tsNNEfEzzV2m3Gf7V00XdBl6WtKPJI1LOiXp8WbLuZjtqyS9LOnBiPii6Xqq0FT4ZyRt7Hm+\nQdLJhmrpKyJOFo+zkl7V3GVL2522vU6SisfZhutZVEScjojzEfG1pGfUomNse0xzwX8uIl4pVnfq\n+M6nqfC/LWmT7etsXyHpbkkHGqplUbZX2r76wrKkWyUdXfy7WuGApF3F8i5JrzVYS18XglS4Uy05\nxrYt6VlJxyLiiZ6XOnV859NYk09xK+f3kpZJ2hsRv2ukkD5s/1Bzo700N9X5822r1fYLkrZq7q/N\nTkt6RNKfJb0k6fuSPpZ0V0S04k22BerdqrlT/pB0QtK9F66pm2T7l5L+Kul9SV8Xqx/W3HV/K49v\nWXT4AUnR4QckRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKn/A1UjndJKb7JbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24ea2cd9cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_road(list_):\n",
    "    N = len(list_)\n",
    "    length_road = 6\n",
    "    roads = []\n",
    "    end = []\n",
    "    for i in range(N-length_road):\n",
    "        #print(np.all(list_[i:i+length_road] > 0))\n",
    "        roads += [np.all(list_[i:i+length_road] > 0)]\n",
    "    for i in range(N, 0, -1):\n",
    "        end += [np.all(list_[i-length_road:i] > 0)]\n",
    "    roads += end[:length_road]\n",
    "    roads = fill_holes(roads)\n",
    "    return roads\n",
    "\n",
    "def fill_holes(list_):\n",
    "    max_hole = 3\n",
    "    idx = np.where(np.array(list_))[0]\n",
    "    distances = idx[1:] - idx[0:-1]\n",
    "    tofill = np.where(distances <= max_hole)[0]\n",
    "    for i in tofill:\n",
    "        list_[i] = True\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 25) (25, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24ea5dadf60>"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl5oyfqkp45eaMn6pKeOXmvp/DaKaf+vPuNwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24ea5d819e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = []\n",
    "C = []\n",
    "for i in range(25):\n",
    "    L += [check_road(labeled[i, :])]\n",
    "    C += [check_road(labeled[:, i])]\n",
    "L = np.asarray(L)\n",
    "C = np.asarray(C).T\n",
    "print(L.shape, C.shape)\n",
    "roads = (L+C).astype(int)\n",
    "plt.imshow(roads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
