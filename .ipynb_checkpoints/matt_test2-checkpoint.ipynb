{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LeakyReLU, Input, Reshape, Permute, Average\n",
    "from keras.layers import Conv2D, MaxPooling2D, Concatenate, Lambda, Activation, GlobalAveragePooling2D, Conv2DTranspose, GlobalAveragePooling1D\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os,sys\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import timeit\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the files for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 400, 400, 3) (100, 400, 400)\n"
     ]
    }
   ],
   "source": [
    "# Directory and files name\n",
    "train_dir = \"training/\"\n",
    "tr_image_dir = train_dir + \"images/\"\n",
    "tr_label_dir = train_dir + \"groundtruth/\"\n",
    "\n",
    "tr_image_files = os.listdir(tr_image_dir)\n",
    "tr_label_files = os.listdir(tr_label_dir)\n",
    "\n",
    "# Number of training samples\n",
    "N = len(tr_image_files)\n",
    "\n",
    "# Load the images and ground truth\n",
    "img_train = []\n",
    "label_train = []\n",
    "for i in range(N):\n",
    "    img = mpimg.imread(tr_image_dir + tr_image_files[i])\n",
    "    label = mpimg.imread(tr_label_dir + tr_label_files[i])\n",
    "    \n",
    "    img_train.append(img)\n",
    "    label_train.append(label)\n",
    "\n",
    "# Keep only sub-set of images\n",
    "NUM_IMAGES = N\n",
    "\n",
    "img_train = np.asarray(img_train[:NUM_IMAGES])\n",
    "label_train = np.asarray(label_train[:NUM_IMAGES])\n",
    "\n",
    "print(img_train.shape, label_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "label_patches = [img_crop(label_train[i, :, :], PATCH_SIZE, PATCH_SIZE) for iNUM_IMAGES in range(NUM_IMAGES)]\n",
    "label_train =  np.asarray([label_patches[i][j] for i in range(len(label_patches)) for j in range(len(label_patches[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute features for each image patch\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "def value_to_class(v):\n",
    "    df = np.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "label_train = np.asarray([value_to_class(np.mean(label_train[i])) for i in range(len(label_train))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance the training dataset w/ sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 400\n",
    "WINDOW_SIZE = 52 # 18px - PATCH_SIZE - 18px\n",
    "NB_WINDOWS = (IMG_SIZE/PATCH_SIZE)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_mirror_boundary_conditions(coord, dim):\n",
    "    \"\"\"\n",
    "    Return the correct coordinate according to mirror boundary conditions\n",
    "        coord: a coordinate (x or y) in the image\n",
    "        dim: the length of the axis of said coordinate\n",
    "    \"\"\"\n",
    "    # If the coordinate is outside of the bounds of the axis, take its reflection inside the image\n",
    "    if coord < 0:\n",
    "        coord = -coord\n",
    "    elif coord >= dim:\n",
    "        coord =  2*(dim-1) - coord % (2*(dim-1))\n",
    "    # Else, do nothing\n",
    "    return int(coord)\n",
    "\n",
    "def get_window(image, window_size, corner_coordinates, patch_size):\n",
    "    \"\"\"\n",
    "    Get a window in image, centered on a patch, taking into account boundary conditions\n",
    "        image: a numpy array representing our image\n",
    "        window_size: an even number specifying the size of the window\n",
    "        corner_coordinates: a list containing the x-y coordinates of the patch's upleft pixel\n",
    "        path_size: an even number specifying the size of the central patch\n",
    "    \"\"\"\n",
    "    # Get convenient variables\n",
    "    window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    nrows, ncols, nchannels = image.shape\n",
    "    window = np.zeros((window_size, window_size, nchannels))\n",
    "    \n",
    "    # Fill in the window array with pixels of the image\n",
    "    for i in range(window_size):\n",
    "        # Apply mirror boundary conditions on the x-coordinate\n",
    "        i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i, nrows)\n",
    "        for j in range(window_size):\n",
    "            # Same for the y-coordinate\n",
    "            j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j, ncols)\n",
    "            # Fill in the window with the corresponding pixel\n",
    "            window[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_to_the_right(image, window, corner_coordinates, patch_size):\n",
    "    nrows, ncols, _ = image.shape\n",
    "    window_size = len(window)\n",
    "    #window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    step = patch_size\n",
    "    \n",
    "    shifted = np.roll(window, -step, axis=1)\n",
    "    for i in range(window_size):\n",
    "        i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i, nrows)            \n",
    "        for j in range(window_size-step, window_size):\n",
    "            j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j + step, ncols)\n",
    "            shifted[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return shifted\n",
    "\n",
    "def shift_to_the_bottom(image, window, corner_coordinates, patch_size):\n",
    "    nrows, ncols, _ = image.shape\n",
    "    window_size = len(window)\n",
    "    #window_radius = window_size/2\n",
    "    border_size = (window_size - patch_size)/2\n",
    "    i_patch_corner, j_patch_corner = (corner_coordinates[0], corner_coordinates[1])\n",
    "    i_window_corner, j_window_corner = (i_patch_corner - border_size, j_patch_corner - border_size)\n",
    "    step = patch_size\n",
    "    \n",
    "    shifted = np.roll(window, -step, axis=0)\n",
    "    for j in range(window_size):\n",
    "        j_mirrored = apply_mirror_boundary_conditions(j_window_corner + j, ncols)\n",
    "        for i in range(window_size-step, window_size):\n",
    "            i_mirrored = apply_mirror_boundary_conditions(i_window_corner + i + step, nrows)\n",
    "            shifted[i, j, :] = image[i_mirrored, j_mirrored, :]\n",
    "    return shifted\n",
    "\n",
    "def sliding_window(image, window_size, patch_size):\n",
    "    \"\"\"\n",
    "    Construct a list of sliding windows of given size on an image.\n",
    "    The windows, centered on a patch, will slide from left to right and from up to down.\n",
    "        image: a numpy array representing our image\n",
    "        window_size: an even number specifying the size of the window\n",
    "        patch_size: the size of the central patch\n",
    "    \"\"\"\n",
    "    nrows, ncols, _ = image.shape\n",
    "    windows = []\n",
    "    i = 0\n",
    "    row_windows = [get_window(image, window_size, [i, 0], patch_size)]\n",
    "    for j in range(patch_size, ncols-1, patch_size):\n",
    "        #print(j)\n",
    "        row_windows += [shift_to_the_right(image, row_windows[-1], [i, j], patch_size)]\n",
    "    windows += row_windows\n",
    "    #print('===')\n",
    "    for i in range(patch_size, nrows-1, patch_size):\n",
    "        #print(i)\n",
    "        row_windows = [shift_to_the_bottom(image, row_windows[int(j/patch_size)], [i, j], patch_size) \n",
    "                       for j in range(0, ncols-1, patch_size)]\n",
    "        #print(len(row_windows))\n",
    "        windows += row_windows\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute(img_train, window_size, patch_size):\n",
    "    train_data = []\n",
    "    #train_labels = []\n",
    "    for im, i in zip(img_train, range(len(img_train))):\n",
    "        w_im = sliding_window(im, window_size, patch_size)\n",
    "        #w_labels = sliding_window(labels[:, :, np.newaxis], window_size, step)\n",
    "        train_data += w_im\n",
    "        #train_labels += w_labels\n",
    "        #path = './windows_train_patch/' + str(i)\n",
    "        #os.makedirs(path, exist_ok=True)\n",
    "        #for wi, j in zip(w_im, range(len(w_im))):\n",
    "            #img_name = path + '/im_' + str(j) + '.png'\n",
    "            #plt.imsave(img_name, wi)\n",
    "            #label_name = path + '/label_' + str(j) + '.png'\n",
    "            #plt.imsave(label_name, wl[:,:,0])\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#img_train = np.asarray(compute(img_train, WINDOW_SIZE, PATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#a = np.array(range(10*10))\n",
    "#a = a.reshape((10, 10))\n",
    "#print(a)\n",
    "#aa = get_window(a[:,:,np.newaxis], 5, [5,5])[:,:,0]\n",
    "#print('\\n')\n",
    "#print(aa)\n",
    "#print('\\n')\n",
    "#print(shift_to_the_bottom(a[:,:,np.newaxis], aa[:,:,np.newaxis], [5,5], 2)[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "#IMG_PATCH_SIZE = 52\n",
    "#TRAINING_SIZE = 62500\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 15\n",
    "a = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model0(IMG_PATCH_SIZE, TRAINING_SIZE):\n",
    "    model0 = Sequential()\n",
    "    model0.add(Conv2D(32, 2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(Conv2D(32, 2))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model0.add(Dropout(0.25))\n",
    "\n",
    "    model0.add(Conv2D(64, 2))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(Conv2D(64, 2))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model0.add(Dropout(0.25))\n",
    "\n",
    "    model0.add(Flatten())\n",
    "    model0.add(Dense(128))\n",
    "    model0.add(Dropout(0.5))\n",
    "    model0.add(LeakyReLU(alpha=a))\n",
    "    model0.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "def fire(x, squeeze, expand):\n",
    "    x = Conv2D(squeeze, 1)(x)\n",
    "    x = LeakyReLU(alpha=a)(x)\n",
    "    e11 = Conv2D(expand, 1)(x)\n",
    "    e11 = LeakyReLU(alpha=a)(e11)\n",
    "    e33 = Conv2D(expand, 1)(x)\n",
    "    e33 = LeakyReLU(alpha=a)(e33)\n",
    "    return Concatenate(axis=3)([e11, e33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(IMG_PATCH_SIZE, TRAINING_SIZE):\n",
    "    inputs = Input(shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS))\n",
    "    x = Conv2D(32, kernel_size=3, strides=2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS))(inputs)\n",
    "    x = LeakyReLU(alpha=a)(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    x = fire(x, squeeze=8, expand=16)\n",
    "    x = fire(x, squeeze=8, expand=16)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    '''x = fire(x, squeeze=32, expand=128)\n",
    "    x = fire(x, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    x = fire(x, squeeze=48, expand=192)\n",
    "    x = fire(x, squeeze=48, expand=192)\n",
    "    x = fire(x, squeeze=64, expand=256)\n",
    "    x = fire(x, squeeze=64, expand=256)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)'''\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model1 = Model(inputs, x)\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model2(IMG_PATCH_SIZE, TRAINING_SIZE):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(32, 2, input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(Conv2D(32, 2))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Dropout(0.25))\n",
    "\n",
    "    model2.add(Conv2D(64, 2))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(Conv2D(64, 2))\n",
    "    model2.add(LeakyReLU(alpha=a))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Dropout(0.25))\n",
    "\n",
    "    model2.add(Conv2D(2, 1))\n",
    "    model2.add(Conv2DTranspose(1, kernel_size=IMG_PATCH_SIZE - 1, padding='valid'))\n",
    "    #model.add(Reshape((-1, IMG_PATCH_SIZE * IMG_PATCH_SIZE)))\n",
    "    #model.add(Permute((2,1)))\n",
    "    model2.add(GlobalAveragePooling2D())\n",
    "    model2.add(Activation('sigmoid'))\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in model.layers:\n",
    "    #print(layer.input_shape,layer.output_shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 25s 394us/step - loss: 0.6112 - acc: 0.7039\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 23s 365us/step - loss: 0.6092 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 23s 361us/step - loss: 0.6083 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 22s 354us/step - loss: 0.6085 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 22s 354us/step - loss: 0.6080 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 22s 357us/step - loss: 0.6080 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 23s 361us/step - loss: 0.6080 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 22s 355us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 22s 356us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 22s 355us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 23s 368us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 23s 363us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 23s 366us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 22s 358us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 22s 356us/step - loss: 0.6076 - acc: 0.7040\n",
      "62500/62500 [==============================] - 8s 133us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 21s 329us/step - loss: 0.6083 - acc: 0.7040\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 16s 264us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 17s 267us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 17s 272us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 16s 259us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 18s 288us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 17s 272us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 16s 249us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 16s 250us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 17s 268us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 17s 268us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 16s 252us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 16s 251us/step - loss: 0.6074 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 16s 252us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 16s 250us/step - loss: 0.6075 - acc: 0.7040\n",
      "62500/62500 [==============================] - 7s 104us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 22s 347us/step - loss: 0.6093 - acc: 0.7040\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 21s 334us/step - loss: 0.6081 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 22s 345us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 20s 325us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 21s 331us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 20s 328us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 21s 330us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 21s 338us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 21s 336us/step - loss: 0.6074 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 20s 327us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 20s 325us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 22s 354us/step - loss: 0.6074 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 22s 351us/step - loss: 0.6073 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 21s 331us/step - loss: 0.6072 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 21s 338us/step - loss: 0.6073 - acc: 0.7040\n",
      "62500/62500 [==============================] - 7s 114us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 26s 413us/step - loss: 0.6109 - acc: 0.7039\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 24s 384us/step - loss: 0.6086 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 24s 391us/step - loss: 0.6080 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 24s 391us/step - loss: 0.6081 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 24s 391us/step - loss: 0.6080 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 24s 388us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 24s 390us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 25s 393us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 24s 391us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 24s 390us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 25s 402us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 24s 386us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 24s 387us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 24s 390us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 24s 389us/step - loss: 0.6075 - acc: 0.7040\n",
      "62500/62500 [==============================] - 9s 146us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 18s 284us/step - loss: 0.6083 - acc: 0.7039\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 16s 259us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 16s 258us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 16s 258us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 16s 258us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 16s 260us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 16s 262us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 16s 259us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 16s 264us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 16s 261us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 16s 260us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 16s 258us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 16s 257us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 16s 257us/step - loss: 0.6074 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 16s 260us/step - loss: 0.6074 - acc: 0.7040\n",
      "62500/62500 [==============================] - 7s 110us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 24s 384us/step - loss: 0.6090 - acc: 0.7038\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 22s 357us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62500/62500 [==============================] - 22s 347us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 21s 343us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 21s 344us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 21s 344us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 21s 344us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 22s 344us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 22s 344us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 22s 352us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 22s 345us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 22s 345us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 22s 345us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 22s 345us/step - loss: 0.6074 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 22s 345us/step - loss: 0.6074 - acc: 0.7040\n",
      "62500/62500 [==============================] - 8s 126us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 28s 452us/step - loss: 0.6105 - acc: 0.7040\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 26s 419us/step - loss: 0.6090 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 26s 420us/step - loss: 0.6083 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 26s 421us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 26s 420us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 26s 419us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 26s 420us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 26s 417us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 26s 417us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 26s 418us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 26s 418us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 26s 420us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 26s 419us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 26s 419us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 26s 420us/step - loss: 0.6075 - acc: 0.7040\n",
      "62500/62500 [==============================] - 10s 158us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 19s 297us/step - loss: 0.6085 - acc: 0.7038\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 17s 268us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 17s 265us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 17s 268us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 17s 266us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 37991s 608ms/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 18s 283us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 17s 273us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 17s 271us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 17s 270us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 17s 270us/step - loss: 0.6074 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 17s 272us/step - loss: 0.6074 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 17s 271us/step - loss: 0.6073 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 17s 270us/step - loss: 0.6072 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 17s 271us/step - loss: 0.6073 - acc: 0.7040\n",
      "62500/62500 [==============================] - 9s 149us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 29s 459us/step - loss: 0.6092 - acc: 0.7036\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 25s 399us/step - loss: 0.6080 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 26s 413us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 26s 408us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 25s 404us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 25s 404us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 24s 391us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 24s 386us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 25s 393us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 24s 390us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 24s 378us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 24s 391us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 24s 377us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 24s 381us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 24s 389us/step - loss: 0.6075 - acc: 0.7040\n",
      "62500/62500 [==============================] - 9s 140us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 32s 508us/step - loss: 0.6102 - acc: 0.7039\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 27s 437us/step - loss: 0.6082 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 28s 441us/step - loss: 0.6082 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 28s 442us/step - loss: 0.6080 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 28s 442us/step - loss: 0.6082 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 28s 449us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 29s 469us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 31s 500us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 29s 463us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 29s 460us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 28s 449us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 27s 439us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 30s 485us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 28s 450us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 28s 446us/step - loss: 0.6075 - acc: 0.7040\n",
      "62500/62500 [==============================] - 11s 171us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 19s 311us/step - loss: 0.6085 - acc: 0.7040\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 18s 288us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 17s 278us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 17s 271us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62500/62500 [==============================] - 18s 284us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 18s 285us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 17s 276us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 18s 283us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 17s 272us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 17s 273us/step - loss: 0.6077 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 17s 274us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 17s 274us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 17s 273us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 17s 272us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 17s 272us/step - loss: 0.6075 - acc: 0.7040\n",
      "62500/62500 [==============================] - 8s 124us/step\n",
      "Epoch 1/15\n",
      "62500/62500 [==============================] - 29s 465us/step - loss: 0.6090 - acc: 0.7038\n",
      "Epoch 2/15\n",
      "62500/62500 [==============================] - 26s 410us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 3/15\n",
      "62500/62500 [==============================] - 28s 441us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 4/15\n",
      "62500/62500 [==============================] - 27s 429us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 5/15\n",
      "62500/62500 [==============================] - 26s 411us/step - loss: 0.6079 - acc: 0.7040\n",
      "Epoch 6/15\n",
      "62500/62500 [==============================] - 26s 411us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 7/15\n",
      "62500/62500 [==============================] - 26s 411us/step - loss: 0.6078 - acc: 0.7040\n",
      "Epoch 8/15\n",
      "62500/62500 [==============================] - 26s 412us/step - loss: 0.6076 - acc: 0.7040\n",
      "Epoch 9/15\n",
      "62500/62500 [==============================] - 26s 417us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 10/15\n",
      "62500/62500 [==============================] - 28s 454us/step - loss: 0.6074 - acc: 0.7040\n",
      "Epoch 11/15\n",
      "62500/62500 [==============================] - 28s 443us/step - loss: 0.6075 - acc: 0.7040\n",
      "Epoch 12/15\n",
      "62500/62500 [==============================] - 27s 425us/step - loss: 0.6074 - acc: 0.7040\n",
      "Epoch 13/15\n",
      "62500/62500 [==============================] - 28s 453us/step - loss: 0.6073 - acc: 0.7040\n",
      "Epoch 14/15\n",
      "62500/62500 [==============================] - 27s 428us/step - loss: 0.6073 - acc: 0.7040\n",
      "Epoch 15/15\n",
      "62500/62500 [==============================] - 26s 415us/step - loss: 0.6073 - acc: 0.7040\n",
      " 1408/62500 [..............................] - ETA: 44s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-db321c2637cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\Nicolas\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[1;32m    920\u001b[0m                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                                    sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\Nicolas\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1690\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m                                steps=steps)\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32mD:\\Users\\Nicolas\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1364\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m                     \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\Nicolas\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\Nicolas\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_window_size = np.nan\n",
    "best_model = np.nan\n",
    "best_score = 0\n",
    "\n",
    "LR = 0.001\n",
    "DECAY = 0.00000\n",
    "adam = Adam(lr=LR, decay=DECAY)\n",
    "\n",
    "for window_size in range(20, 60, 2):\n",
    "    data_train = np.asarray(compute(img_train, window_size, 16))\n",
    "    training_size = data_train.shape[0]\n",
    "    num_model = 0\n",
    "    for model in [model0(window_size, training_size), model1(window_size, training_size), model2(window_size, training_size)]:\n",
    "        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "        model.fit(data_train, label_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS)\n",
    "        score = model.evaluate(data_train, label_train)[1]\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = num_model\n",
    "            best_window_size = window_size\n",
    "        num_model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "DECAY = 0.00000\n",
    "adam = Adam(lr=LR, decay=DECAY)\n",
    "\n",
    "#model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "\n",
    "#model.fit(img_train, label_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#score = model.evaluate(train_data, train_labels)\n",
    "#score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
